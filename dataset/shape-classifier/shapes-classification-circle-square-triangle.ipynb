{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8489635,"sourceType":"datasetVersion","datasetId":4184221}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-18T10:19:33.361215Z","iopub.execute_input":"2023-12-18T10:19:33.362984Z","iopub.status.idle":"2023-12-18T10:19:33.905652Z","shell.execute_reply.started":"2023-12-18T10:19:33.362899Z","shell.execute_reply":"2023-12-18T10:19:33.904452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:21:21.610963Z","iopub.execute_input":"2023-12-18T10:21:21.611813Z","iopub.status.idle":"2023-12-18T10:21:37.453364Z","shell.execute_reply.started":"2023-12-18T10:21:21.611737Z","shell.execute_reply":"2023-12-18T10:21:37.451155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths to your train and test datasets\ntrain_data_dir = '/kaggle/input/geometric-shapes-circle-square-triangle/train'\ntest_data_dir = '/kaggle/input/geometric-shapes-circle-square-triangle/test'\n\n\n\n# Image size and channels\nimg_width, img_height, img_channels = 56, 56, 3","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:22:11.371084Z","iopub.execute_input":"2023-12-18T10:22:11.371929Z","iopub.status.idle":"2023-12-18T10:22:11.379107Z","shell.execute_reply.started":"2023-12-18T10:22:11.371883Z","shell.execute_reply":"2023-12-18T10:22:11.3773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Createing a data generator with data augmentation for the training set\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,              # Rescale pixel values to be between 0 and 1\n    rotation_range=30,           # Randomly rotate images in the range of -30 to +30 degrees\n    width_shift_range=0.1,       # Randomly shift images horizontally by 10%\n    height_shift_range=0.1,      # Randomly shift images vertically by 10%\n    zoom_range=0.2,              # Randomly zoom into images by 20%\n    horizontal_flip=True        # Randomly flip images horizontally\n)\n\n# Only rescaling for the test set\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Generateing batches of augmented data for training and testing\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=32,\n    class_mode='categorical'    # Use categorical mode for multi-class classification\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=32,\n    class_mode='categorical'    # Use categorical mode for multi-class classification\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:23:26.656566Z","iopub.execute_input":"2023-12-18T10:23:26.65709Z","iopub.status.idle":"2023-12-18T10:23:26.703772Z","shell.execute_reply.started":"2023-12-18T10:23:26.65705Z","shell.execute_reply":"2023-12-18T10:23:26.702394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the CNN Model\nmodel = models.Sequential([\n    # Convolutional layer with 32 filters, each of size (3, 3), and ReLU activation function\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, img_channels)),\n    \n    # MaxPooling layer to down-sample the spatial dimensions\n    layers.MaxPooling2D((2, 2)),\n    \n    # Convolutional layer with 64 filters, each of size (3, 3), and ReLU activation function\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    \n    # MaxPooling layer to down-sample the spatial dimensions\n    layers.MaxPooling2D((2, 2)),\n    \n    # Convolutional layer with 128 filters, each of size (3, 3), and ReLU activation function\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    \n    # Flatten layer to flatten the output of the previous layer\n    layers.Flatten(),\n    \n    # Fully connected layer with 128 neurons and ReLU activation function\n    layers.Dense(128, activation='relu'),\n    \n    # Output layer with 3 neurons (assuming 3 classes) and softmax activation function for multi-class classification\n    layers.Dense(3, activation='softmax')\n])\n\n# Display the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:24:25.011629Z","iopub.execute_input":"2023-12-18T10:24:25.01206Z","iopub.status.idle":"2023-12-18T10:24:25.348678Z","shell.execute_reply.started":"2023-12-18T10:24:25.012014Z","shell.execute_reply":"2023-12-18T10:24:25.347223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compileing the model\nmodel.compile(optimizer='adam',            # Optimizer: Adam\n              loss='categorical_crossentropy',  # Loss function: Categorical Crossentropy\n              metrics=['accuracy'])            # Evaluation metric: Accuracy\n\n# Training the model\nhistory = model.fit(train_generator,                  # Training data generator\n          epochs=15,                        # Number of training epochs\n          validation_data=validation_generator)  # Validation data generator\n\n# Check the accuracy of the model on the test set\nscore = model.evaluate(validation_generator)  # Evaluate the model on the validation set\nprint(score)\nprint('Test loss:', score[0])                 # Display the test loss\nprint('Test accuracy:', score[1])             # Display the test accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:25:26.151229Z","iopub.execute_input":"2023-12-18T10:25:26.151729Z","iopub.status.idle":"2023-12-18T10:26:07.317151Z","shell.execute_reply.started":"2023-12-18T10:25:26.151682Z","shell.execute_reply":"2023-12-18T10:26:07.316068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary library\nimport matplotlib.pyplot as plt\n\n# Plotting the training and validation accuracy over epochs\nplt.plot(history.history['accuracy'], color='red', label='train')         # Plotting training accuracy in red\nplt.plot(history.history['val_accuracy'], color='blue', label='validation')  # Plotting validation accuracy in blue\n\nplt.legend()\nplt.show()\n\n#The resulting plot will provide a visual representation of how well our model is learning from the training data and generalizing to unseen validation data over the training epochs.","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:28:35.82151Z","iopub.execute_input":"2023-12-18T10:28:35.822634Z","iopub.status.idle":"2023-12-18T10:28:36.070525Z","shell.execute_reply.started":"2023-12-18T10:28:35.822554Z","shell.execute_reply":"2023-12-18T10:28:36.068371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation loss over epochs\nplt.plot(history.history['loss'], color='red', label='train')          # Plot training loss in red\nplt.plot(history.history['val_loss'], color='blue', label='validation')  # Plot validation loss in blue\n\nplt.legend()\nplt.show()\n\n# The resulting plot provides a visual representation of how well the model is minimizing the loss function during training and validation.","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:30:52.919959Z","iopub.execute_input":"2023-12-18T10:30:52.920863Z","iopub.status.idle":"2023-12-18T10:30:53.133631Z","shell.execute_reply.started":"2023-12-18T10:30:52.920798Z","shell.execute_reply":"2023-12-18T10:30:53.131754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:31:16.701164Z","iopub.execute_input":"2023-12-18T10:31:16.701621Z","iopub.status.idle":"2023-12-18T10:31:17.04143Z","shell.execute_reply.started":"2023-12-18T10:31:16.701579Z","shell.execute_reply":"2023-12-18T10:31:17.039452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img1 = cv2.imread('/kaggle/input/geometric-shapes-circle-square-triangle/Real Images/triangle.png')\ntest_img2 = cv2.imread('/kaggle/input/geometric-shapes-circle-square-triangle/Real Images/circle.png')\ntest_img3 = cv2.imread('/kaggle/input/geometric-shapes-circle-square-triangle/Real Images/square.png')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:32:27.969175Z","iopub.execute_input":"2023-12-18T10:32:27.96962Z","iopub.status.idle":"2023-12-18T10:32:28.035759Z","shell.execute_reply.started":"2023-12-18T10:32:27.969585Z","shell.execute_reply":"2023-12-18T10:32:28.033867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.subplot(131)\nplt.imshow(test_img1)\nplt.title('test_img1')\n\nplt.subplot(132)\nplt.imshow(test_img2)\nplt.title('test_img2')\n\nplt.subplot(133)\nplt.imshow(test_img3)\nplt.title('test_img3')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:32:49.910169Z","iopub.execute_input":"2023-12-18T10:32:49.910539Z","iopub.status.idle":"2023-12-18T10:32:50.357816Z","shell.execute_reply.started":"2023-12-18T10:32:49.910507Z","shell.execute_reply":"2023-12-18T10:32:50.355842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_img1.shape)\nprint(test_img2.shape)\nprint(test_img3.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:12:03.83188Z","iopub.execute_input":"2023-12-18T11:12:03.83344Z","iopub.status.idle":"2023-12-18T11:12:03.84653Z","shell.execute_reply.started":"2023-12-18T11:12:03.833382Z","shell.execute_reply":"2023-12-18T11:12:03.843797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img1 = cv2.resize(test_img1,(56,56))\ntest_img2 = cv2.resize(test_img2,(56,56))\ntest_img3 = cv2.resize(test_img3,(56,56))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:12:15.70669Z","iopub.execute_input":"2023-12-18T11:12:15.707493Z","iopub.status.idle":"2023-12-18T11:12:15.726587Z","shell.execute_reply.started":"2023-12-18T11:12:15.707455Z","shell.execute_reply":"2023-12-18T11:12:15.724218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting to shape 56*56*3\ntest_image1 = test_img1.reshape((1,56,56,3))\ntest_image2 = test_img2.reshape((1,56,56,3))\ntest_image3 = test_img3.reshape((1,56,56,3))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:12:24.39948Z","iopub.execute_input":"2023-12-18T11:12:24.399861Z","iopub.status.idle":"2023-12-18T11:12:24.406466Z","shell.execute_reply.started":"2023-12-18T11:12:24.399831Z","shell.execute_reply":"2023-12-18T11:12:24.405363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = tf.concat([test_image1, test_image2, test_image3], axis=0)\npredictions = model.predict(input_tensor)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:12:35.255809Z","iopub.execute_input":"2023-12-18T11:12:35.256235Z","iopub.status.idle":"2023-12-18T11:12:35.790358Z","shell.execute_reply.started":"2023-12-18T11:12:35.256201Z","shell.execute_reply":"2023-12-18T11:12:35.788719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:12:46.081591Z","iopub.execute_input":"2023-12-18T11:12:46.082387Z","iopub.status.idle":"2023-12-18T11:12:46.091284Z","shell.execute_reply.started":"2023-12-18T11:12:46.082349Z","shell.execute_reply":"2023-12-18T11:12:46.089653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}